# MySQL 45 讲



### 一条SQL语句是如何查询的

逻辑架构图如下：

![image-20230425202353593](D:\MyBlog\MyBlog\database\assets\image-20230425202353593.png)



大体来说，MySQL可分为 Service 和 存储引擎层两部分。

-   Service 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 Mysql 的大多数核心服务功能，以及所有的内置函数，（如时间、日期、数学和加密函数等），所有跨存储引擎的功能都在service层实现，比如存储过程、触发器。视图等。
-  存储引擎层负责数据的存储和提取，其架构模式是插件式，支持 InnoDB 、MyISAM 、Memory 等多个存储引擎。常用的是 InnoDB (从mysql 5.5.5版本开始为默认存储引擎)



**大多数情况下不建议使用查询缓存，为啥？ 因为其弊往往大于利。**

​        查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。



### 一条SQL语句是如何执行更新语句的

我们可能听过 DBA 说，MySQL可以恢复到半个月内任意一秒的状态，下面就来讲解一下！





从一个表的一条更新语句来看，下面是这个表的创建语句，这个表有一个主键 ID 和一个整型字段 c：

``` mysql
create table T(ID int primary key,c int);
```



如果要将 ID=2 这一行的值加 1，SQL 语句就会这么写：

``` mysql
update T set c = c + 1 where ID = 2;
```



**可以确定的说，查询语句的那一套流程，更新语句也会走一遍。**

但与查询流程不一样的是，更新流程还涉及到两个重要的日志模块， **redo log （重做日志）** 和   **binlog （归档日志）** 。这两个日志在设计上有很多有意思的地方，这些设计思路可以引用到我们自己的程序里。

#### redo log   ------重要的日志模块

> ​		不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。
> 如果有人要赊账或者还账的话，掌柜一般有两种做法：
>
> ​				一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；
> ​				另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。
>
> ​		在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。
>
> ​		这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？
>
> ​		同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。
>
> ​		而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。
>
> ​		具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。
>
> ​		如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。
>
> ​		与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。

![image-20230425212203944](D:\MyBlog\MyBlog\database\assets\image-20230425212203944.png)



> ​		write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录
> 更新到数据文件。
>
> ​		write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。
>
> ​		有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。
>
> ​		要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。



#### 重要日志模块： binlog

​		其实从 MySQL 整体上看，就有两块：一块是 Server 层，它主要做的是MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 **redo log** 是 **InnoDB 引擎特有的日志**，而 **Server 层也有自己的日志，称为binlog（归档日志）**。



> 可能会有人问，**为什么需要两份日志**？
>
> ​		因为**最开始 MySQL 里并没有 InnoDB 引擎**。MySQL 自带的引擎是 MyISAM，但是MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。



**这两种日志有以下三点不同。**



> 1.redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
>
> 
>
> 2.redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
>
> 
>
> 3.redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。





​		有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的
update 语句时的内部流程。

> 1.执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
>
> 
>
> 2.执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
>
> 
>
> 3.引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
>
> 
>
> 4.执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
>
> 
>
> 5.执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。



​		这里我给出这个 **update 语句的执行流程图**，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。

![image-20230425213958932](D:\MyBlog\MyBlog\database\assets\image-20230425213958932.png)



​		**最后三步看上去可能有点“绕”，将 redo log 的写入拆成两个步骤：prepare 和 commit ，这就是 “ 两阶段提交 ”。**



#### 两阶段提交



> ​		为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？
>
> ​		前面我们说过了，binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：
>
> ​		首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。
>
> ​		好了，说完了数据恢复过程，我们回来说说，为什么日志需要“两阶段提交”。这里不妨用反证法来进行解释。
>
> ​		由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。
>
> 

​		仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？



> 1. 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。
>
> 2. 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同
>
>   
>
>   ​		可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。
>
>   ​		你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。





### 事务隔离： 为什么你改了我还看不见？



简单来说，事务就是要保证一组数据库的操作，要么全部成功，要么全部失败。在MySQL 中，事务支持是在引擎层实现的。MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如MySQL原生的MyISAM引擎就不支持事务，这也是其被 InnoDB 替代的主要原因之一。



#### 隔离性与隔离级别



提到事务我们肯定会想到  ACID(Atomicity，Consistency，Isolation，Durability , 即原子性、一致性、隔离性、持久性)。

接下来主要讲解一下“隔离性”。



当数据库上有多个事务同时执行时，就可能出现脏读 （dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）等问题，为了解决这些问题就有了“隔离级别”的概念。



在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释：



> **读未提交**是指，一个事务还没提交时，它做的变更就能被别的事务看到。
>
> **读提交**是指，一个事务提交之后，它做的变更才会被其他事务看到。
>
> **可重复读**是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
>
> **串行化**，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。



``` mysql
create table T(c int) engine = InnoDB;
insert into T(c) values(1);
```



|         事务A          | 事务B        |
| :--------------------: | ------------ |
| 启动事务，查询得到值 1 | 启动事务     |
|                        | 查询得到值 1 |
|                        | 将 1 改成 2  |
|     查询得到值 V1      |              |
|                        | 提交事务 B   |
|     查询得到值 V2      |              |
|       提交事务 A       |              |
|     查询得到值 V3      |              |



> 若隔离级别是“读未提交”， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2
>
> 若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A看到。所以， V3 的值也是 2。
>
> 若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。
>
> 若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。



------



###  深入浅出索引-1

> 一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本500 页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。



#### 常见的索引模型

·比较常见的有**哈希表、有序数组和搜索树**。



> 哈希表是一种以 键-值 存储数据的结构，哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把 value 放在数组的这个位置。
>
> 
>
> 不可避免的，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。



假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：

![image-20230510090736314](D:\MyBlog\MyBlog\database\assets\image-20230510090736314.png)

> 图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。
>
> 需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。
>
> 你可以设想下，如果你现在要找身份证号在 [ID_card_X, ID_card_Y] 这个区间的所有用户，就必须全部扫描一遍了。
>
> 所以，**哈希表这种结构适用于只有等值查询的场景**，比如 Memcached 及其他一些NoSQL 引擎。



而**有序数组在等值查询和范围查询场景中性能就很优秀**，还是以上面的例子进行解释：

![image-20230510091535762](D:\MyBlog\MyBlog\database\assets\image-20230510091535762.png)



> 这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查 ID_card_n2 对应的名字，用二分法就可以快速得到，这个时间复杂度是O(log(N))。
>
> 同时很显然，这个索引结构支持范围查询。你要查身份证号在 [ID_card_X, ID_card_Y] 区间的 User，可以先用二分法找到 ID_card_X（如果不存在 ID_card_X，就找到大于ID_card_X 的第一个 User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证号，退出循环。
>
> 如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。
>
> 所以，**有序数组索引只适用于静态存储引擎**， 比如你要记录某年某个地方的所有人口信息等，此类不会再修改的数据。



#### todo





------



### 深入浅出索引 -2



#### todo



------



### 全局锁和表锁 ：给表加个字段怎么有这么多的障碍？

